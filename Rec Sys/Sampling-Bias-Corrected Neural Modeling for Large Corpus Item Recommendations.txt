Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations

ABSTRACT

Many recommendation systems retrieve and score items from a very large corpus. A common recipe to handle data sparsity and power-law item distribution is to learn item representations from its content features. Apart from many content-aware systems based on matrix factorization, we consider a modeling framework using two-tower neural net, with one of the towers (item tower) encoding a wide variety of item content features. A general recipe of training such two-tower models is to optimize loss functions calculated from in-batch negatives, which are items sampled from a random minibatch. However, in-batch loss is subject to sampling biases, potentially hurting model performance, particularly in the case of highly skewed distribution. In this paper, we present a novel algorithm for estimating item frequency from streaming data. Through theoretical analysis and simulation, we show that the proposed algorithm can work without requiring fixed item vocabulary, and is capable of producing unbiased estimation and being adaptive to item distribution change. We then apply the sampling-bias-corrected modeling approach to build a large scale neural retrieval system for YouTube recommendations. The system is deployed to retrieve personalized suggestions from a corpus with tens of millions of videos. We demonstrate the effectiveness of sampling-bias correction through offline experiments on two real-world datasets. We also conduct live A/B testings to show that the neural retrieval system leads to improved recommendation quality for YouTube.

1 INTRODUCTION

Recommendation systems help users discover content of interest across many internet services, including video recommendations [12, 18], app suggestions [9], and online advertisement targeting [38]. In many cases, these systems connect billions of users to items from an extremely large corpus of content, often in the scale of millions to billions, under stringent latency requirements. A common practice is to treat the recommendation as a retrieval-andranking problem, and design a two-phase system [9, 12]. That is, a scalable retrieval model first retrieves a small fraction of related items from a large corpus, and a fully-blown ranking model reranks the retrieved items based on one or multiple objectives such as clicks or user-ratings. In this work, we focus on building a realworld learned retrieval system for personalized recommendation that scales up to millions of items.

Given a triplet of {user , context , item}, a common solution to build a scalable retrieval model is: 1) learn query and item representations for {user , context } and {item} respectively; and 2) use a simple scoring function (e.g., dot product) between query and item representations to get recommendations tailored for the query. Context often represents variables with dynamic nature, such as time of day, and devices users are using. The representation learning problem is typically challenging in two ways: 1) The corpus of items could be extremely large for many industrial-scale applications; 2) Training data collected from users' feedback is very sparse for most items, and thus causes model predictions to have large variance for long-tail content. Facing the well-reported cold-start problem, real-world systems need to be adaptive to data distribution change to better surface fresh content.

Inspired by the Netflix prize [32], matrix factorization (MF) based modeling has been widely adopted for learning query and item latent factors in building retrieval systems. Under the MF framework, a body of recommendation research (e.g., [21, 34]) addresses the aforementioned challenges in learning from a large corpus. The common idea is to leverage the content features of query and item. Content features can be roughly defined as a wide variety of features describing items beyond item id. For example, content features of a video can be the visual and audio features extracted from video frames. MF-based models are usually only capable of capturing second-order interactions of features, and thus have limited power in representing a collection of features with various formats.

In recent years, motivated by the success of deep learning in computer vision and natural language processing, there is a large amount of work applying deep neural networks (DNNs) to recommendations. Deep representations are well suited for encoding complicated user states and item content features in low-dimensional embedding space. In this paper, we explore the applications of  two-tower DNNs in building retrieval models. Figure 1 provides an illustration of the two-tower model architecture where left and right towers encode {user , context } and {item} respectively. Twotower DNN is generalized from the multi-class classification neural network [19], a multi-layer perceptron (MLP) model, where the right tower of Figure 1 is simplified to a single layer with item embeddings. As a result, the two-tower model architecture is capable of modeling the situation where label has structures or content features. MLP model is commonly trained with many sampled negatives from a fixed vocabulary of items. In contrast, with deep item tower, it is typically inefficient to sample and train on many negatives due to item content features and shared network parameters for computing all item embeddings.

We consider batch softmax optimization, where item probability is calculated over all items in a random batch, as a general recipe of training two-tower DNNs. However, as shown in our experiments, batch softmax is subject to sampling bias and could severely restrict the model performance without any correction. Importance sampling and the corresponding bias reduction have been studied in MLP model [4, 5]. Inspired by these works, we propose to correct sampling bias of batch softmax using estimated item frequency. In contrast to MLP model where the output item vocabulary is stationary, we target the streaming data situation with vocabulary and distribution changes over time. We propose a novel algorithm to sketch and estimate item frequency via gradient descent. In addition, we apply the bias-corrected modeling and scale it to build a personalized retrieval system for YouTube recommendations. We also introduce a sequential training strategy, designed to incorporate streaming data, along with the indexing and serving components of the system.

The major contributions of this paper include:

Streaming Frequency Estimation. We propose a novel algorithm to estimate item frequency from a data stream, subject to vocabulary and distribution shifts.We offer analytical results to show the variance and bias of the estimation. We also provide simulation that demonstrates the efficacy of our approach in capturing data dynamics.

Modeling Framework. We provide a generic modeling framework for building large-scale retrieval systems. In particular, we incorporate the estimated item frequency in a cross entropy loss for the batch softmax to reduce the sampling bias of in-batch items.

YouTube Recommendation. We describe how we apply the modeling framework to build a large-scale retrieval system for YouTube recommendations. We introduce the endto- end system including the training, indexing, and serving components.

Offline and Live Experiments. We perform offline experiments on two real-world datasets and demonstrate the effectiveness of sampling bias correction. We also show that our retrieval system built for YouTube leads to improved engagement metrics in live experiments.

2 RELATEDWORK

In this section, we give an overview of the related work, and highlight the connections to our contributions.

2.1 Content-Aware and Neural Recommenders

Utilizing content features of users and items is critical for improving generalization and mitigating cold-start problems. There is a line of research focusing on incorporating content features in the classic matrix factorization framework [23]. For instance, the generalized matrix factorization models, e.g., SVDFeature [8] and Factorization Machine [33], can be applied to incorporate item content features. These models are able to capture up to bi-linear, i.e., second-order, interactions between features. In recent years, deep neural networks (DNNs) have been shown effective in improving recommendation accuracy. Due to the nature of being highly nonlinear, DNNs offer a larger capacity for capturing complicated feature interactions [6, 35], compared to traditional factorization approaches. He et al. [21] directly applies the intuition of collaborative filtering (CF), and offers a neural CF (NCF) architecture for modeling user-item interactions. In the NCF framework, users and items embeddings are concatenated and passed through a multi-layer neural network to get the final prediction. Our work differs from NCF in two aspects: 1) we leverage a two-tower neural network for modeling useritem interactions so that the inference can be conducted over a large corpus of items in sub-linear time; 2) learning NCF relies on point-wise loss (such as squared or log loss), while we introduce a multi-class softmax loss and explicitly model item frequency.

On a separate line of work, deep and recurrent models such as LSTM are applied to incorporate temporal information and historical events in recommendations, e.g., [12, 14]. Besides the learning of separate user and item representations, there is another set of works focusing on designing neural networks particularly for learned to rank systems. Notably, multi-task learning has been a central technique in optimizing multiple objectives for complicated recommenders [27, 28]. Cheng et al. [9] introduces a wide-n-deep framework with jointly trained wide linear models and deep neural networks.

2.2 Extreme Classification

Softmax is one of the most commonly used functions in designing models for the prediction of a large output space up to millions of labels. Lots of research has been focusing on training softmax classification models for a large number of classes, ranging from language tasks [5, 29] to recommenders [12]. When the number of classes is extremely large, a widely used technique to speed up training is to sample a subset of classes. Bengio et al. [5] shows that a good sampling distribution should be adaptive to the model's output distribution. To avoid the complication of computing the sampling distribution, many real-world models apply a simple distribution such as unigram or uniform as a proxy. Recently, Blanc et al. [7] designs an efficient and adaptive kernel based sampling method. Despite the success of sampled softmax in various domains, it is not applicable to the case where label has content features. Adaptive sampling in this case also remains an open problem. Various works have shown that tree-based label structures, e.g., hierarchical softmax [30], are useful for building large-scale classification models while significantly reducing inference time. These approaches typically require a predefined tree structure based on certain categorical attributes. As a result, they are not suitable for incorporating a wide variety of input features.

2.3 Two-tower Models

Building neural networks with two towers has recently become a popular approach in several natural language tasks including modeling sentence similarities [31], response suggestions [24], and text-based information retrieval [17, 37]. Our work contributes to this line of research, particularly demonstrating the effectiveness of two-tower models in building large-scale recommenders. Compared to many language tasks in the aforementioned literature, it is worth noting that we focus on the problem with a much larger corpus size, which is common in our target applications such as YouTube. Through live experiments, we find that explicitly modeling item frequency is critical for improving retrieval accuracy in this setting. Yet, this problem is not well addressed in existing works.

3 MODELING FRAMEWORK

We consider a common setup for recommendation problems where we have a set of queries and items. Queries and items are representsed by feature vectors {xi }N i=1 and {yj }M j=1 respectively. Here xi   X,yj   Y are both mixtures of a wide variety of features (e.g., sparse IDs and dense features) and could be in a very high dimensional space. The goal is to retrieve a subset of items given a query. In personalization scenario, we assume user and context are fully captured in xi . Note that we begin with a finite number of queries and items to explain the intuition. Our modeling framework works without such an assumption. 

We aim to build a model with two parameterized embedding functions u : X yy Rd yyyy Rk , v : Y yy Rd yyyy Rk that map model parameter xxx   Rd and features of query and candidates to a kdimensional embedding space. We focus on the case where u, v are represented by two deep neural networks as illustrated Figure 1. The output of the model is the inner product of two embeddings, namely, s(x,y) = xxu(x, xxx), v(y, xxx)\xe2\x9f\xa9. The goal is to learn model parameter xxx from a training dataset of T examples, denoted by T := {(xi ,yi , ri )}Ti =1, where (xi ,yi ) denotes the pair of query xi and item yi , and ri   R is the associated reward for each pair.

Intuitively, the retrieval problem can be treated as a multi-class classification problem with continuous rewards. In classification tasks where each label is equally important, ri = 1 for all positive pairs. In recommenders, ri can be extended to capture various degrees of user engagement with a certain candidate. For example, in news recommendations, ri can be the time a user spent on a certain article. Given a query x, a common choice for the probability distribution of picking candidate y from M items {yj }M j=1 is based on the softmax function, i.e.,

By further incorporating rewards ri , we consider the following weighted log-likelihood as the loss function

When M is very large, it is not feasible to include all candidate examples in computing the partition function, i.e., the denominator in Equation (1). A common idea is to use a subset of items in constructing the partition function.We focus on dealing with streaming data. As a result, unlike training MLP models where negatives are sampled from a fixed corpus, we consider only using in-batch items [22] as negatives for all queries from the same batch. Precisely, given a mini-batch of B pairs {(xi ,yi , ri )}B i=1, for each i   [B], the batch softmax is

In-batch items are normally sampled from a power-law distribution in our target applications. As a result, Equation (3) introduces a large bias towards full softmax: popular items are overly penalized as negatives due to the high probability of being included in a batch. Inspired by the logQ correction used in sampled softmax model [5], we correct each logit s(xi ,yj ) by the following equation sc (xi ,yj ) = s(xi ,yj ) ppp log(pj ).

Here pj denotes the sampling probability of item j in a random batch. We defer the estimation of pj to the next section.

With the correction, we have

Then plugging the above term into Equation (2) leads to

which is the batch loss function. Running SGD with learning rate \xce\xb3 yields the model parameter update as

Note that LB does not require a fixed set of queries or candidates. Accordingly, Equation (5) can be applied to streaming training data whose distribution changes over time. See Algorithm 1 for a full description of our proposed approach.

e.g., [2, 10, 25], for approximate maximum inner product search (MIPS) problems. Specifically, compact representations of high dimensional embeddings are built through quantization [20] and end-to-end learning of coarse and product quantizers [36].

Normalization and Temperature. Empirically, we find that adding embedding normalization, i.e., u(x, xxx) xxxu(x, xxx)/xxu(x, xxx)xx2, v(y, xxx) xxxv(y, xxx)/xxv(y, xxx)xx2, improves model trainability and thus leads to better retrieval quality. In addition, a temperature \xcf\x84 is added to each logit to sharpen the predictions, namely, s(x,y) = xxu(x, xxx),v(y, xxx)\xe2\x9f\xa9/\xcf\x84 . In practice \xcf\x84 is a hyper-parameter tuned to maximize retrieval metrics such as recall or precision.

4 STREAMING FREQUENCY ESTIMATION

In this section, we elaborate the streaming frequency estimation used in Algorithm 1.

Consider a stream of random batches, where each batch contains a set of items. The problem is to estimate the probability of hitting each item y in a batch. A critical design criterion is to have a fully distributed estimation to support distributed training when there are multiple training jobs (i.e., workers).

In either single-machine or distributed training, a unique global step, which represents the number of data batches consumed by the trainer, is associated with each sampled batch. In a distributed setting, the global step is typically synchronized among multiple workers through parameter servers. We can leverage the global step and convert the estimation of frequency p of an item to the estimation of \xce\xb4, which denotes the average number of steps between two consecutive hits of the item. For example, if one item gets sampled every 50 steps, then we have p = 0.02. The use of global step offer us two advantages: 1) Multiple workers are implicitly synchronized in frequency estimation via reading and modifying the global step; 2) Estimating \xce\xb4 can be achieved by a simple moving average update, which is adaptive to distribution change.

As using fixed item vocabulary is not practical, we apply hash arrays to record the sampling information of streaming IDs. Note that introducing hashing could cause potential hash collision. We will revisit this issue and propose an improved algorithm at the end of this section. As shown in Algorithm 2, we keep two arrays A and B with size H. Suppose h is a hash function that maps any item to an integer in [H], the mapping can be based on the ID or any other thumbnail feature values. Then for a given item y, A[h(y)] records the latest step when y is sampled, and B[h(y)] contains the estimated \xce\xb4 of y. We use array A to help updating array B. Once item y occurs in step t , we update array B by B[h(y)] xxx (1 ppp \xce\xb1) \xc2\xb7 B[h(y)] + \xce\xb1 \xc2\xb7 (t ppp A[h(y)]). (6) After B is updated, we assign t to A[h(y)].

For each item, suppose the number of steps between two consecutive hits follows a distribution represented by random variable \xce\x94 with mean \xce\xb4 = E(\xce\x94). Here our goal is to estimate \xce\xb4 from a stream of samples. Whenever an item occurs in a batch at step t , t ppp A[v(y)] is a new sample of \xce\x94. Accordingly, the above update can be understood as running SGD with fixed learning rate \xce\xb1 to learn the mean of this random variable. Formally, in the case of no collision, the next result shows the bias and variance of this online estimation.

Proposition 4.1. Suppose {\xce\x941, \xce\x942, ..., \xce\x94t } is a sequence of i.i.d. samples of random variable \xce\x94. Let \xce\xb4 = E [\xce\x94]. Consider an online estimation where for i   [t ] and \xce\xb1   (0, 1), \xce\xb4i = (1 ppp \xce\xb1) \xc2\xb7 \xce\xb4ippp1 + \xce\xb1 \xc2\xb7 \xce\x94i . The estimation bias is given by E(\xce\xb4t ) ppp \xce\xb4 = (1 ppp \xce\xb1)t \xce\xb40 ppp (1 ppp \xce\xb1)tppp1\xce\xb4 . (7) For the variance, we have

Proof. By taking expectation, we have E [\xce\xb4i ] = (1 ppp \xce\xb1) \xc2\xb7 E(\xce\xb4ippp1) + \xce\xb1 \xc2\xb7 \xce\xb4 . By induction on t , we have (7). For the variance, we have

Equation (7) indicates that the bias |E [\xce\xb4t ] ppp \xce\xb4 | yyyy 0 as t yyyy \xe2\x88\x9e. Moreover, an ideal initialization \xce\xb40 = \xce\xb4/(1 ppp \xce\xb1) can lead to an unbiased estimation in every step. Equation (8) gives an upper bound on the estimation variance. The learning rate \xce\xb1 affects the variance in two folds: 1) higher rate causes a faster decrease of the first term that depends on initialization error; 2) lower rate reduces the second term which depends on the variance of \xce\x94 and does not decrease over time.

To get the estimated sampling probability p\xcb\x86 of y, we can simply perform p\xcb\x86 = 1/B[h(y)].

Distributed Updates. We consider the distributed training framework presented in [13], where model parameters are distributed over a set of servers called parameter servers, and multiple workers process training data independently and communicate with parameter servers to fetch and update model parameters. Algorithm 2 can be extended to this setting. Arrays A, B and the global step parameter are distributed over parameter servers. Each worker executes line 4 via sampling a mini-batch of items. In detail, at step t , A[h(y)], B[h(y)] are fetched from parameter servers. Then A[h(y)], B[h(y)] are updated as shown and sent back. Therefore, the updates in Algorithm 2 can be executed along with the asynchronous stochastic gradient descent training of neural networks.

Multiple Hashings. Inspired by a similar idea in count-min sketch [11], we extend Algorithm 2 to leverage multiple hash functions to mitigate over-estimation of item frequency due to collisions. The improved estimation is presented in Algorithm 3. Updating each array Ai , Bi follows the corresponding steps in Algorithm 2. Each bucket in B could be an under-prediction of the true step gap as it could represent the union of multiple items because of collisions. As a result, for inference, we take the maximum of ourm estimations representing the number of steps between two consecutive hits.

5 NEURAL RETRIEVAL SYSTEM FOR YOUTUBE

We apply the proposed modeling framework and scale it to build a large scale neural retrieval system for one particular product in YouTube. This product generates video recommendations conditioned on a video (called seed video) being watched by a user. The recommendation system consists of two stages: nomination (a.k.a., retrieval) and ranking. At nomination stage, we have multiple nominators that each generates hundreds of video recommendations given constraints of a user and a seed video. These videos are subsequently scored and re-ranked by a fully-blown neural network ranking model. In this section, we focus on building an additional nominator in the retrieval stage, especially on the perspectives of data, model architecture, training, and serving.

5.1 Modeling Overview

The YouTube neural retrieval model we built consists of query and candidate networks. Figure 2 illustrates the general model architecture. At any point of time, the video which a user is watching, i.e., the seed video, provides a strong signal about the user's current interest. As a result, we make use of a large set of seed video features along with the user's watch history. The candidate tower is built to learn from candidate video features.

Training Label. Video clicks are used as positive labels. In addition, for each click, we construct a reward ri to reflect different degrees of user engagement with the video. For example, ri = 0 for clicked videos with little watch time. On the other hand, ri = 1 indicates the whole video got watched. The reward is used as example weight as shown in Equation (4).

Video Features. The video featureswe use include both categorical and dense features. Examples of categorical features include Video Id, and Channel Id. For each of these entities, an embedding layer is created to map each categorical feature to a dense vector. Normally we are dealing with two kinds of categorical features. Some features (e.g., Video id) have strictly one categorical value per video, so we have one embedding vector representing that. Alternatively, one feature (e.g., Video topics) might be a sparse vector of categorical values, and the final embedding representing that feature would be a weighted sum of the embeddings for each of the values in the sparse vector. To handle out-of-vocabulary entities, we randomly assign them to a fixed set of hash buckets, and learn an embedding for each one. Hash buckets are important for model to capture new entities available in YouTube, particularly when sequential training described in Section 5.2 is used.

User Features.We use a user's watch history to capture the user's interest besides the seed video. One example is a sequence of k video ids the user recently watched. We treat the watch history as a bag of words (BOW), and represent it by the average of video id embeddings. In the query tower, user and seed video features are fused in the input layer, which is then passed through a feed forward neural network.

For the same type of IDs, embeddings are shared among the related features. For example, the same set of video id embeddings is used for seed, candidate and users' past watches.We did experiment with non-shared embeddings, but did not observe significant model quality improvement.

5.2 Sequential Training 
Our model is implemented in Tensorflow [1], and trained with distributed gradient descent over many workers and parameter servers. In YouTube, new training data is generated every day, and training datasets are accordingly organized by days. The model training makes use of this sequential structure in the following way. Trainer consumes the data sequentially from the oldest training examples to the most recent training examples. Once the trainer has caught up to the latest day of training data, it waits for the next day's training data to arrive. In this way, the model is able to keep up with latest data distribution shift. Training data is essentially consumed by trainer in a streaming manner. We apply Algorithm 2 (or Algorithm 3 if multiple hashings are used) to estimate item frequency. The online update of Equation (6) enables the model to adapt to new frequency distribution.

5.3 Indexing and Model Serving

The index pipeline in the retrieval system periodically creates a Tensorflow SavedModel for online serving. The index pipeline was built in three stages: candidate example generation, embedding inference, and embedding indexing, as shown in Figure 3. In the first stage, a set of videos are selected from YouTube corpus based on certain criterion. Their features are fetched and added to the candidate examples. In the second stage, right tower of Figure 2 is applied to compute embeddings from candidate examples. In the third stage, we train a Tensorflow-based embedding index model based on tree and quantizied hashing techniques.We gloss over the details as they are not the focus of this paper. Finally, the Saved- Model used in serving is created by stitching the query tower of Figure 2 and the indexing model together.

6 EXPERIMENTS

In this section, we show experimental results to demonstrate the effectiveness of the proposed item frequency estimation and modeling framework.

6.1 Simulation on Frequency Estimation

To evaluate effectiveness of Algorithms 2 & 3, we begin with a simulation study where we first apply each proposed algorithm to fit a fixed item distribution, and then change the distribution after a certain step. To be more precise, in our setting, we use a fixed set of M items and each item is sampled independently according to probabilities qi \xe2\x88\x9d i2 for i   [M] where \xc3\x8d i qi = 1. We conduct the simulation on an input stream where a batch of items B are sampled in each step. Here each item in B is sampled without replacement from qi . Therefore, the item sampling probability we aim to fit is pi = |B| yy qi . We keep the sampling distribution static for the first t steps. We then switch it to qi \xe2\x88\x9d (M ppp 1 ppp i)2 for the remaining steps. To evaluate the estimation accuracy, we use a rescaled L1 distance between the estimated probability set {p\xcb\x86i }i  [M] and {pi }i  [M], precisely 1 2|B| \xc3\x8d i |p\xcb\x86i ppp pi |, as the estimation error. It can be also understood as the total variance between the estimates {q\xcb\x86i }i  [M] and {qi }i  [M].

Specifically, we report: 1) effect of learning rate \xce\xb1, and 2) effect of multiple hashings.

Effect of Learning Rate \xce\xb1. We set M = 1000, B = 128, and use array size H = 5000 for both A and B. In addition, we initialize array A with all zeros and every entry of B with value 100. Distribution is switched at step t = 10000. We use one hash function and run Algorithm 2. Figure 4 shows the estimation errors over the number of global steps for a set of learning rates \xce\xb1. We observe that all three curves converge to a level of error which comes from hashing collisions and estimation variance. With a higher learning rate, the algorithm is more adaptive to distribution change, but the final variance is higher as shown in Proposition 4.1.

 Effect of Multiple Hashings. For the second simulation, we run Algorithm 3 and experiment with various number of hash functions m. Figure 5 shows the curves of estimation error form = 1, 2, 4. We choose different array sizes H for A, B so that the total number of hash buckets remain the same across these three settings. Figure 5 demonstrates the effectiveness of using multiple hash functions to reduce estimation error, even under same number of parameters.

6.2 Wikipedia Page Retrieval

In this section,we conduct page-retrieval experiments on the Wikipedia dataset [16] to show the efficacy of the sampling-bias-corrected batch loss 4.

Dataset. We consider the task of predicting intra-site links between Wikipedia pages. For a given pair of source and destination pages (x,y), label is 1 if there is a link from x to y, and 0 otherwise. Each page is represented by a set of content features including page URL, a bag-of-words representation of the set of n-grams in the title, and a bag-of-words representation of the page categories. We experiment with the English graph, which consists of 5.3M pages, 430M links, 510K title n-grams, and 403.4K unique categories.

Model. We treat the link prediction as a retrieval problem, where given a source page, the task is to retrieve the destination pages from the page corpus. As a result, we train a two-tower neural network where the left and right towers map the features of source and destination features respectively. The input feature embeddings are shared among the two towers. Each tower has two fully connected ReLU layers with dimensions [512, 128].

Baselines. We compare the proposed sampling-bias-corrected batch softmax (correct-sfx) with batch softmax without any correction (plain-sfx) as shown in Equation (3), to demonstrate the efficacy of bias correction. In addition, we consider the the mean squared loss which is widely adopted in modeling implicit feedback in recommendations. The loss is a combination of MSE on observed pairs and a regularization term pushing all unseen pairs to a constant prior commonly chosen as 0. Under the framework introduced in Section 3, the loss is

where \xce\xa9 and \xce\xa9c denote the set of observed pairs and its complement, and \xce\xbb is a positive hyperparameter. In matrix factorization, such a loss is typically trained using alternating least squares [23] or coordinate descent methods [3] by writing the regularization term as a matrix-inner-product of two Gramians, which can be computed efficiently for linear embeddings. Very recently, Krichene et al. [26] extends the Gramian computation to non-linear scenarios by SGD estimation. We refer to this method as mse-gramian.

Training and Evaluation. For all methods, we use batch size 1024 and the model is trained with Adagrad [15] and learning rate 0.01 for 10M steps. For frequency estimation, we usem = 1, H = 40M and \xce\xb1 = 0.01. We holdout 10% links for evaluation. We evaluate the model performance by Recall@K, which is essentially the average probability of including true label in top k candidates against the full page corpus. Parameter \xce\xbb in mse-gramian is tuned via line search and we report the best results here. We find that normalizing the output layers always improves model performance and experiment with multiple temperature values \xcf\x84 for plain-sfx and correct-sfx.

Results are summarized in Table 1. For each temperature value, correct-sfx outperforms the corresponding plain-sfx by a large margin. It is interesting to see the effect of temperature on performance, suggesting the necessity to carefully tune this parameter when normalization is applied. We also note that batch softmax based methods lead to better performance than mse-gramian.

6.3 YouTube Experiments

We carry out offline and live experiments on YouTube based on the neural retrieval system introduced in Section 5. The YouTube training data we use includes billions of clicked videos on a daily basis, across many days.

Setup. Recall that the model structure we use is shown in Figure 2. As aforementioned, input feature embeddings are shared between query and candidate towers if they are available to both. We use three-layer DNNs with hidden layer sizes [1024, 512, 128] for both towers. We train the model using Adagrad, learning rate 0.2, and batch size 8192. For frequency estimation, we set H = 50M,m = 1, \xce\xb1 = 0.01. Recall that we apply sequential training as introduced in Section 5.2. For experiments in this section, index of approximately 10M videos chosen from the YouTube corpus is built periodically every few hours. The index corpus is subject to change over time due to, for example, uploads of fresh videos. But it typically covers more than 90% of training examples.

Offline Experiments. We assign ri = 1 for all clicked videos, and evaluate the model performance by the recall when retrieving clicked videos. We simplify the reward function for offline experiments because it is not obvious to define an appropriate offline metric for a continuous reward. To incorporate the sequential training, we evaluate the model performance after day d0 when the trainer completes the catch-up phase, which is set to 15 days, and starts to wait for new data. For each new day after d0, we holdout 10% data for evaluation. To account for a weekly pattern, we report averaged offline results over 7 days, i.e., from d0 + 1 to d0 + 7. The results are presented in Table 2. Again, we see significant improvements from using batch softmax compared to mse-gramian. Also, among the settings with different \xcf\x84 , item-frequency-corrected softmax performs significantly better than the plain softmax. 

Live Experiments. We also conduct live experiments in an A/B testing framework in YouTube. For users in the control group, videos are suggested from the production system. For the treatment group, users are presented with recommendations after adding candidates from the neural retrieval system shown in Figure 2 to the nomination stage. As recommending videos which users like to click is not ideal, for live experiments we train the model with the reward in a way to reflect the users' real engagement with clicked videos. We report the engagement metric aligned with this label. Results are shown in Table 3. As can be seen, adding the neural retrieval system improves the previous production system by a significant margin. Moreover, the model with correct-sfx performs better than the baseline of using plain-sfx by a significant margin, demonstrating the effectiveness of sampling bias correction.

7 CONCLUSION

In this paper, we presented a generic modeling framework for building large scale content-aware retrieval models for industrial-scale applications. We proposed a novel algorithm for estimating item frequency. Theoretical analyses and simulation demonstrated its correctness and effectiveness. We applied the proposed modeling framework to build a neural retrieval system for YouTube recommendations. In particular, to capture the data dynamics of YouTube, we presented a sequential training strategy to which the streaming frequency estimation algorithm could be easily integrated. Offline experiments on both Wikipedia link prediction and YouTube video retrieval showed significant improvements using sampling bias correction. Live experiments in YouTube also showed improvements in user engagement with candidates retrieved from our neural retrieval system.

REFERENCES